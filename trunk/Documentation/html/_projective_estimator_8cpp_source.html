<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>GSoC2011SfM: D:/Travail/These/Determination caracteristiques camera/GSoC/SfM/src/ProjectiveEstimator.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body onload='searchBox.OnSelectItem(0);'>
<!-- Generated by Doxygen 1.7.4 -->
<script type="text/javascript"><!--
var searchBox = new SearchBox("searchBox", "search",false,'Search');
--></script>
<div id="top">
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">GSoC2011SfM&#160;<span id="projectnumber">0.1</span></div>
   <div id="projectbrief">Google Summer of Code 2011: Structure from motion</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li id="searchli">
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
<div class="header">
  <div class="headertitle">
<div class="title">D:/Travail/These/Determination caracteristiques camera/GSoC/SfM/src/ProjectiveEstimator.cpp</div>  </div>
</div>
<div class="contents">
<div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 <span class="preprocessor">#include &quot;ProjectiveEstimator.h&quot;</span>
<a name="l00002"></a>00002 <span class="preprocessor">#include &quot;StructureEstimator.h&quot;</span>
<a name="l00003"></a>00003 <span class="preprocessor">#include &lt;opencv2/core/eigen.hpp&gt;</span>
<a name="l00004"></a>00004 
<a name="l00005"></a>00005 <span class="keyword">using</span> std::vector;
<a name="l00006"></a>00006 <span class="keyword">using</span> cv::Ptr;
<a name="l00007"></a>00007 
<a name="l00008"></a>00008 <span class="keyword">namespace </span>OpencvSfM{
<a name="l00009"></a>00009   <span class="comment">//only for intern usage, no external interface...</span>
<a name="l00010"></a>00010   <span class="comment">//Idea from Snavely : Modeling the World from Internet Photo Collections</span>
<a name="l00011"></a>00011   <span class="comment">//See with libmv team if such a function is usefull:</span>
<a name="l00012"></a>00012   <span class="keywordtype">double</span> robust5Points(<span class="keyword">const</span> libmv::Mat2X &amp;x1, <span class="keyword">const</span> libmv::Mat2X &amp;x2,
<a name="l00013"></a>00013     <span class="keyword">const</span> libmv::Mat3 &amp;K1, <span class="keyword">const</span> libmv::Mat3 &amp;K2,
<a name="l00014"></a>00014     libmv::Mat3 &amp;E)
<a name="l00015"></a>00015   {
<a name="l00016"></a>00016     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> nPoints = x1.cols();
<a name="l00017"></a>00017     CV_DbgAssert( nPoints == x2.cols() );
<a name="l00018"></a>00018     CV_DbgAssert( nPoints &gt;= 5 );<span class="comment">//need 5 points!</span>
<a name="l00019"></a>00019 
<a name="l00020"></a>00020     <a class="code" href="classlibmv_1_1vector.html">libmv::vector&lt;libmv::Mat3&gt;</a> Es;
<a name="l00021"></a>00021     cv::RNG&amp; rng = cv::theRNG();
<a name="l00022"></a>00022     vector&lt;int&gt; masks(nPoints);
<a name="l00023"></a>00023     <span class="keywordtype">double</span> max_error = 1e9;
<a name="l00024"></a>00024 
<a name="l00025"></a>00025     <span class="keywordtype">int</span> num_iter=0, max_iter=nPoints-5;
<a name="l00026"></a>00026     <span class="keywordflow">for</span>(num_iter=0; num_iter&lt;max_iter; ++num_iter)
<a name="l00027"></a>00027     {
<a name="l00028"></a>00028       masks.clear();
<a name="l00029"></a>00029       <span class="keywordtype">int</span> nb_vals=0;
<a name="l00030"></a>00030       <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cpt = 0; cpt &lt; nPoints; cpt++) {
<a name="l00031"></a>00031         masks.push_back(0);
<a name="l00032"></a>00032       }
<a name="l00033"></a>00033       <span class="keywordflow">while</span>( nb_vals &lt; 5 )
<a name="l00034"></a>00034       {
<a name="l00035"></a>00035         <span class="keywordtype">int</span> valTmp = rng(nPoints);
<a name="l00036"></a>00036         <span class="keywordflow">if</span>( masks[valTmp] == 0 )
<a name="l00037"></a>00037         {
<a name="l00038"></a>00038           masks[valTmp] = 1;
<a name="l00039"></a>00039           nb_vals++;
<a name="l00040"></a>00040         }
<a name="l00041"></a>00041       }
<a name="l00042"></a>00042       <span class="comment">//create mask:</span>
<a name="l00043"></a>00043       libmv::Mat2X x1_tmp,x2_tmp;
<a name="l00044"></a>00044       x1_tmp.resize(2,nb_vals);
<a name="l00045"></a>00045       x2_tmp.resize(2,nb_vals);
<a name="l00046"></a>00046       nb_vals=0;
<a name="l00047"></a>00047       <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i;
<a name="l00048"></a>00048       <span class="keywordflow">for</span>( i = 0; i&lt;nPoints; ++i)
<a name="l00049"></a>00049       {
<a name="l00050"></a>00050         <span class="keywordflow">if</span>( masks[i] != 0 )
<a name="l00051"></a>00051         {
<a name="l00052"></a>00052           x1_tmp(0,nb_vals) = x1( 0,i );
<a name="l00053"></a>00053           x1_tmp(1,nb_vals) = x1( 1,i );
<a name="l00054"></a>00054           x2_tmp(0,nb_vals) = x2( 0,i );
<a name="l00055"></a>00055           x2_tmp(1,nb_vals) = x2( 1,i );
<a name="l00056"></a>00056           nb_vals++;
<a name="l00057"></a>00057         }
<a name="l00058"></a>00058       }
<a name="l00059"></a>00059       libmv::FivePointsRelativePose(x1_tmp,x2_tmp,&amp;Es);
<a name="l00060"></a>00060       <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> num_hyp = Es.size();
<a name="l00061"></a>00061       <span class="keywordflow">for</span> (i = 0; i &lt; num_hyp; i++) {
<a name="l00062"></a>00062         
<a name="l00063"></a>00063         libmv::Mat3 F;
<a name="l00064"></a>00064         libmv::FundamentalFromEssential( Es[i], K1, K2, &amp;F );
<a name="l00065"></a>00065 
<a name="l00066"></a>00066         <span class="keywordtype">double</span> error = libmv::SampsonDistance2( F, x1, x2);
<a name="l00067"></a>00067 
<a name="l00068"></a>00068         <span class="keywordflow">if</span> (max_error &gt; error ) {
<a name="l00069"></a>00069             max_error = error;
<a name="l00070"></a>00070             E = Es[i];
<a name="l00071"></a>00071         }
<a name="l00072"></a>00072       }
<a name="l00073"></a>00073     }
<a name="l00074"></a>00074     <span class="keywordflow">return</span> max_error;
<a name="l00075"></a>00075   }
<a name="l00076"></a>00076 
<a name="l00077"></a>00077 
<a name="l00078"></a>00078   ProjectiveEstimator::ProjectiveEstimator(SequenceAnalyzer &amp;sequence,
<a name="l00079"></a>00079     vector&lt;PointOfView&gt;&amp; cameras)
<a name="l00080"></a>00080     :sequence_(sequence),cameras_(cameras)
<a name="l00081"></a>00081   {
<a name="l00082"></a>00082     vector&lt;PointOfView&gt;::iterator itPoV=cameras.begin();
<a name="l00083"></a>00083     <span class="keywordflow">while</span> ( itPoV!=cameras.end() )
<a name="l00084"></a>00084     {
<a name="l00085"></a>00085       addNewPointOfView(*itPoV);
<a name="l00086"></a>00086       itPoV++;
<a name="l00087"></a>00087     }
<a name="l00088"></a>00088   }
<a name="l00089"></a>00089 
<a name="l00090"></a>00090 
<a name="l00091"></a>00091   ProjectiveEstimator::~ProjectiveEstimator(<span class="keywordtype">void</span>)
<a name="l00092"></a>00092   {
<a name="l00093"></a>00093     <span class="comment">//TODO!!!!</span>
<a name="l00094"></a>00094   }
<a name="l00095"></a>00095 
<a name="l00096"></a>00096   <span class="keywordtype">void</span> ProjectiveEstimator::updateTwoViewMotion(vector&lt;TrackOfPoints&gt;&amp; tracks,
<a name="l00097"></a>00097     vector&lt; Ptr&lt; PointsToTrack &gt; &gt; &amp;points_to_track,
<a name="l00098"></a>00098     <span class="keywordtype">int</span> image1, <span class="keywordtype">int</span> image2)
<a name="l00099"></a>00099   {
<a name="l00100"></a>00100     libmv::Mat3 E;
<a name="l00101"></a>00101     Ptr&lt;PointsToTrack&gt; point_img1 = points_to_track[image1];
<a name="l00102"></a>00102     Ptr&lt;PointsToTrack&gt; point_img2 = points_to_track[image2];
<a name="l00103"></a>00103     <span class="comment">//first extract points matches:</span>
<a name="l00104"></a>00104     libmv::Mat2X x1,x2;
<a name="l00105"></a>00105     <span class="comment">//for each points:</span>
<a name="l00106"></a>00106     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> key_size = tracks.size();
<a name="l00107"></a>00107     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i;
<a name="l00108"></a>00108     vector&lt;TrackOfPoints&gt; matches;
<a name="l00109"></a>00109     
<a name="l00110"></a>00110     <span class="keywordflow">for</span> (i=0; i &lt; key_size; ++i)
<a name="l00111"></a>00111     {
<a name="l00112"></a>00112       TrackOfPoints &amp;track = tracks[i];
<a name="l00113"></a>00113       <span class="keywordflow">if</span>( track.containImage(image1) &amp;&amp; track.containImage(image2) )
<a name="l00114"></a>00114         matches.push_back(track);
<a name="l00115"></a>00115     }
<a name="l00116"></a>00116     x1.resize(2,matches.size());
<a name="l00117"></a>00117     x2.resize(2,matches.size());
<a name="l00118"></a>00118 
<a name="l00119"></a>00119     key_size = matches.size();
<a name="l00120"></a>00120     vector&lt;cv::Vec2d&gt; pointImg1,pointImg2;
<a name="l00121"></a>00121     <span class="keywordflow">for</span> (i=0; i &lt; key_size; ++i)
<a name="l00122"></a>00122     {
<a name="l00123"></a>00123       TrackOfPoints &amp;track = matches[i];
<a name="l00124"></a>00124       cv::DMatch match = track.toDMatch(image1, image2);
<a name="l00125"></a>00125       
<a name="l00126"></a>00126       pointImg1.push_back( cv::Vec2d(point_img1-&gt;getKeypoint(match.trainIdx).pt.x,
<a name="l00127"></a>00127         point_img1-&gt;getKeypoint(match.trainIdx).pt.y) );
<a name="l00128"></a>00128       pointImg2.push_back( cv::Vec2d( point_img2-&gt;getKeypoint(match.queryIdx).pt.x,
<a name="l00129"></a>00129         point_img2-&gt;getKeypoint(match.queryIdx).pt.y) );
<a name="l00130"></a>00130     }
<a name="l00131"></a>00131     vector&lt;cv::Vec2d&gt; pointNorm1 = cameras_[image1].getIntraParameters()-&gt;
<a name="l00132"></a>00132       pixelToNormImageCoordinates(pointImg1);
<a name="l00133"></a>00133     vector&lt;cv::Vec2d&gt; pointNorm2 = cameras_[image2].getIntraParameters()-&gt;
<a name="l00134"></a>00134       pixelToNormImageCoordinates(pointImg2);
<a name="l00135"></a>00135     key_size = pointNorm1.size();
<a name="l00136"></a>00136     <span class="keywordflow">for</span> (i=0; i &lt; key_size; ++i)
<a name="l00137"></a>00137     {
<a name="l00138"></a>00138       x1(0,i) = -pointNorm1[i][0];
<a name="l00139"></a>00139       x1(1,i) = -pointNorm1[i][1];
<a name="l00140"></a>00140       x2(0,i) = -pointNorm2[i][0];
<a name="l00141"></a>00141       x2(1,i) = -pointNorm2[i][1];
<a name="l00142"></a>00142     }
<a name="l00143"></a>00143     
<a name="l00144"></a>00144     <span class="keywordtype">double</span> error = robust5Points( x1, x2,
<a name="l00145"></a>00145       intra_params_[image1], intra_params_[image2], E );
<a name="l00146"></a>00146 
<a name="l00147"></a>00147     std::cout&lt;&lt;<span class="stringliteral">&quot;max_error: &quot;</span>&lt;&lt;error&lt;&lt;std::endl;
<a name="l00148"></a>00148 
<a name="l00149"></a>00149     <span class="comment">//From this essential matrix extract relative motion:</span>
<a name="l00150"></a>00150     libmv::Mat3 R;
<a name="l00151"></a>00151     libmv::Vec3 t;
<a name="l00152"></a>00152     libmv::Vec2 x1Col, x2Col;
<a name="l00153"></a>00153     x1Col &lt;&lt; x1(0,15), x1(1,15);
<a name="l00154"></a>00154     x2Col &lt;&lt; x2(0,15), x2(1,15);
<a name="l00155"></a>00155     <span class="keywordtype">bool</span> ok = libmv::MotionFromEssentialAndCorrespondence( E,
<a name="l00156"></a>00156       intra_params_[image1], x1Col,
<a name="l00157"></a>00157       intra_params_[image2], x2Col,
<a name="l00158"></a>00158       &amp;R, &amp;t);
<a name="l00159"></a>00159 
<a name="l00160"></a>00160     rotations_[image2] = R * rotations_[image1];
<a name="l00161"></a>00161     translations_[image2] = t + R * translations_[image1];
<a name="l00162"></a>00162 
<a name="l00163"></a>00163     <span class="comment">//update camera&#39;s structure:</span>
<a name="l00164"></a>00164     cv::Mat newRotation,newTranslation;
<a name="l00165"></a>00165     cv::eigen2cv( rotations_[image2], newRotation );
<a name="l00166"></a>00166     cv::eigen2cv( translations_[image2], newTranslation );
<a name="l00167"></a>00167     cameras_[image2].setRotationMatrix( newRotation );
<a name="l00168"></a>00168     cameras_[image2].setTranslationVector( newTranslation );
<a name="l00169"></a>00169   }
<a name="l00170"></a>00170 
<a name="l00172"></a>00172   <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TMat&gt;
<a name="l00173"></a>00173   <span class="keyword">inline</span> <span class="keywordtype">double</span> FrobeniusNorm(<span class="keyword">const</span> TMat &amp;A) {
<a name="l00174"></a>00174     <span class="keywordflow">return</span> sqrt(A.array().abs2().sum());
<a name="l00175"></a>00175   }
<a name="l00176"></a>00176   <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TMat&gt;
<a name="l00177"></a>00177   <span class="keyword">inline</span> <span class="keywordtype">double</span> FrobeniusDistance(<span class="keyword">const</span> TMat &amp;A, <span class="keyword">const</span> TMat &amp;B) {
<a name="l00178"></a>00178     <span class="keywordflow">return</span> FrobeniusNorm(A - B);
<a name="l00179"></a>00179   }
<a name="l00180"></a>00180   <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TVec&gt;
<a name="l00181"></a>00181   <span class="keyword">inline</span> <span class="keywordtype">double</span> DistanceL2(<span class="keyword">const</span> TVec &amp;x, <span class="keyword">const</span> TVec &amp;y) {
<a name="l00182"></a>00182     <span class="keywordflow">return</span> (x - y).norm();
<a name="l00183"></a>00183   }
<a name="l00184"></a>00184 
<a name="l00185"></a>00185   <span class="comment">// Normalize a vector with the L2 norm, and return the norm before it was</span>
<a name="l00186"></a>00186   <span class="comment">// normalized.</span>
<a name="l00187"></a>00187   <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TVec&gt;
<a name="l00188"></a>00188   <span class="keyword">inline</span> <span class="keywordtype">double</span> NormalizeL2(TVec *x) {
<a name="l00189"></a>00189     <span class="keywordtype">double</span> norm = x-&gt;norm();
<a name="l00190"></a>00190     *x /= norm;
<a name="l00191"></a>00191     <span class="keywordflow">return</span> norm;
<a name="l00192"></a>00192   }
<a name="l00194"></a>00194 
<a name="l00195"></a><a class="code" href="class_opencv_sf_m_1_1_projective_estimator.html#a27cb31f243dd15841c2f223400524ec1">00195</a>   <span class="keywordtype">void</span> <a class="code" href="class_opencv_sf_m_1_1_projective_estimator.html#a27cb31f243dd15841c2f223400524ec1">ProjectiveEstimator::computeReconstruction</a>(vector&lt;PointOfView&gt;&amp; camReal)
<a name="l00196"></a>00196   {
<a name="l00197"></a>00197     vector&lt;TrackOfPoints&gt;&amp; tracks = sequence_.<a class="code" href="class_opencv_sf_m_1_1_sequence_analyzer.html#af7c11e97664c050782bfc2d1808b219e">getTracks</a>();
<a name="l00198"></a>00198     vector&lt; Ptr&lt; PointsToTrack &gt; &gt; &amp;points_to_track = sequence_.<a class="code" href="class_opencv_sf_m_1_1_sequence_analyzer.html#aefda449985e3013c6ac2adc5f61151d4">getPoints</a>();
<a name="l00199"></a>00199     <a class="code" href="class_opencv_sf_m_1_1_images_graph_connection.html" title="This class modelizes the images graph connections.">ImagesGraphConnection</a> &amp;images_graph = sequence_.getImgGraph();
<a name="l00200"></a>00200     <span class="keywordtype">double</span> ransac_threshold = 0.4 * sequence_.getImage(0).rows / 100.0;
<a name="l00201"></a>00201     <span class="comment">//now create the graph:</span>
<a name="l00202"></a>00202     
<a name="l00203"></a>00203     <span class="keywordtype">int</span> img1,img2;
<a name="l00204"></a>00204     <span class="keywordtype">int</span> nbMatches = images_graph.<a class="code" href="class_opencv_sf_m_1_1_images_graph_connection.html#a96ff89db7e87560208a9bcda7f66d6bd">getHighestLink</a>(img1,img2);
<a name="l00205"></a>00205     vector&lt;ImageLink&gt; bestMatches;
<a name="l00206"></a>00206     images_graph.<a class="code" href="class_opencv_sf_m_1_1_images_graph_connection.html#a72329276aeacf384241795e3541db218">getOrderedLinks</a>(bestMatches, 100, nbMatches);
<a name="l00207"></a>00207     <span class="keywordtype">double</span> min_inliners=1e7;
<a name="l00208"></a>00208     <span class="keywordtype">int</span> index_of_min=0;
<a name="l00209"></a>00209     cv::Mat minFundamental;
<a name="l00210"></a>00210     <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cpt=0;cpt&lt;bestMatches.size();cpt++)
<a name="l00211"></a>00211     {
<a name="l00212"></a>00212       <span class="comment">//construct the homography and choose the worse matches:</span>
<a name="l00213"></a>00213       <span class="comment">//(see Snavely &quot;Modeling the World from Internet Photo Collections&quot;)</span>
<a name="l00214"></a>00214       std::vector&lt;cv::Point2f&gt; pointsImg1, pointsImg2;
<a name="l00215"></a>00215       vector&lt;uchar&gt; status;
<a name="l00216"></a>00216       points_to_track[bestMatches[cpt].imgSrc]-&gt;getKeyMatches(tracks,
<a name="l00217"></a>00217         bestMatches[cpt].imgDest, pointsImg1);
<a name="l00218"></a>00218       points_to_track[bestMatches[cpt].imgDest]-&gt;getKeyMatches(tracks,
<a name="l00219"></a>00219         bestMatches[cpt].imgSrc, pointsImg2);
<a name="l00220"></a>00220 
<a name="l00221"></a>00221       <span class="comment">//compute the homography:</span>
<a name="l00222"></a>00222       cv::findHomography(pointsImg1,pointsImg2,status,CV_RANSAC,
<a name="l00223"></a>00223         ransac_threshold );
<a name="l00224"></a>00224       <span class="comment">//count the inliner points:</span>
<a name="l00225"></a>00225       <span class="keywordtype">double</span> inliners=0;
<a name="l00226"></a>00226       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i=0;i&lt;status.size();++i)
<a name="l00227"></a>00227       {
<a name="l00228"></a>00228         <span class="keywordflow">if</span>( status[i] != 0 )
<a name="l00229"></a>00229           inliners++;
<a name="l00230"></a>00230       }
<a name="l00231"></a>00231       <span class="keywordtype">double</span> percent_inliner = inliners/<span class="keyword">static_cast&lt;</span><span class="keywordtype">double</span><span class="keyword">&gt;</span>(pointsImg1.size());
<a name="l00232"></a>00232       <span class="keywordflow">if</span>( percent_inliner &lt; min_inliners )
<a name="l00233"></a>00233       {
<a name="l00234"></a>00234         min_inliners = percent_inliner;
<a name="l00235"></a>00235         index_of_min = cpt;
<a name="l00236"></a>00236         minFundamental = cv::findFundamentalMat(pointsImg1, pointsImg2,
<a name="l00237"></a>00237           status, cv::FM_LMEDS);
<a name="l00238"></a>00238       }
<a name="l00239"></a>00239     }
<a name="l00240"></a>00240     
<a name="l00241"></a>00241     <span class="comment">//we will start the reconstruction using bestMatches[index_of_min]</span>
<a name="l00242"></a>00242     <span class="comment">//to avoid degenerate cases such as coincident cameras</span>
<a name="l00243"></a>00243     img1 = bestMatches[index_of_min].imgSrc;
<a name="l00244"></a>00244     img2 = bestMatches[index_of_min].imgDest;
<a name="l00245"></a>00245     updateTwoViewMotion(tracks, points_to_track, img1, img2);
<a name="l00246"></a>00246 
<a name="l00247"></a>00247     
<a name="l00249"></a>00249     std::cout&lt;&lt;<span class="stringliteral">&quot;best between &quot;</span>&lt;&lt;img1&lt;&lt;<span class="stringliteral">&quot; and &quot;</span>&lt;&lt;img2&lt;&lt;std::endl;
<a name="l00250"></a>00250     libmv::Mat3 rotation_mat,rot_real,rot_relativ;
<a name="l00251"></a>00251     cv::cv2eigen(camReal[img1].getRotationMatrix(),rotation_mat);
<a name="l00252"></a>00252     cv::cv2eigen(camReal[img2].getRotationMatrix(),rot_real);
<a name="l00253"></a>00253     libmv::Vec3 translation_vec,trans_real,trans_relative;
<a name="l00254"></a>00254     cv::cv2eigen(camReal[img1].getTranslationVector(),translation_vec);
<a name="l00255"></a>00255     cv::cv2eigen(camReal[img2].getTranslationVector(),trans_real);
<a name="l00256"></a>00256 
<a name="l00257"></a>00257     libmv::RelativeCameraMotion(rotation_mat, translation_vec,
<a name="l00258"></a>00258       rot_real, trans_real,
<a name="l00259"></a>00259       &amp;rot_relativ, &amp;trans_relative);
<a name="l00260"></a>00260 
<a name="l00261"></a>00261     translation_vec = translations_[img2] + rotations_[img1] * translation_vec;
<a name="l00262"></a>00262     NormalizeL2(&amp;translation_vec);
<a name="l00263"></a>00263     NormalizeL2(&amp;trans_real);
<a name="l00264"></a>00264 
<a name="l00265"></a>00265     std::cout&lt;&lt;<span class="stringliteral">&quot;translation computed:&quot;</span>&lt;&lt;std::endl&lt;&lt;translation_vec&lt;&lt;std::endl;
<a name="l00266"></a>00266     std::cout&lt;&lt;<span class="stringliteral">&quot;translation real:&quot;</span>&lt;&lt;std::endl&lt;&lt;trans_real&lt;&lt;std::endl&lt;&lt;std::endl;
<a name="l00267"></a>00267 
<a name="l00268"></a>00268     std::cout&lt;&lt;<span class="stringliteral">&quot;rotation computed:&quot;</span>&lt;&lt;std::endl&lt;&lt;cameras_[img2].getRotationMatrix()&lt;&lt;std::endl;
<a name="l00269"></a>00269     std::cout&lt;&lt;<span class="stringliteral">&quot;rotation real:&quot;</span>&lt;&lt;std::endl&lt;&lt;rot_real&lt;&lt;std::endl&lt;&lt;std::endl;
<a name="l00270"></a>00270     std::cout&lt;&lt;<span class="stringliteral">&quot;Relative rotation real:&quot;</span>&lt;&lt;std::endl&lt;&lt;rot_relativ&lt;&lt;std::endl&lt;&lt;std::endl;
<a name="l00271"></a>00271 
<a name="l00272"></a>00272     <span class="keywordtype">double</span> dist = FrobeniusDistance(rotation_mat, rot_real);
<a name="l00273"></a>00273     <span class="keywordtype">double</span> dist1 = DistanceL2(translation_vec, trans_real);
<a name="l00274"></a>00274     std::cout&lt;&lt;dist&lt;&lt;<span class="stringliteral">&quot;; &quot;</span>&lt;&lt;dist1&lt;&lt;std::endl;
<a name="l00276"></a>00276     
<a name="l00277"></a>00277     
<a name="l00278"></a>00278     camReal[img1] = cameras_[img1];
<a name="l00279"></a>00279     camReal[img2] = cameras_[img2];
<a name="l00280"></a>00280 
<a name="l00281"></a>00281     <a class="code" href="class_opencv_sf_m_1_1_structure_estimator.html" title="This class tries to find the 3D structure using a sequence and cameras fully parameterized.">StructureEstimator</a> se(sequence_, camReal);
<a name="l00282"></a>00282     vector&lt;TrackOfPoints&gt; points3DTrack;
<a name="l00283"></a>00283     se.<a class="code" href="class_opencv_sf_m_1_1_structure_estimator.html#affcc671ccaa76684f4c7b60277da2815">computeTwoView</a>(img1, img2, points3DTrack);
<a name="l00284"></a>00284     vector&lt;cv::Vec3d&gt; points3D;
<a name="l00285"></a>00285     <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cpt=0;cpt&lt;points3DTrack.size();++cpt)
<a name="l00286"></a>00286       points3D.push_back(points3DTrack[cpt]);
<a name="l00287"></a>00287 
<a name="l00288"></a>00288     <span class="comment">//now for each point of view, we draw the picture and these points projected:</span>
<a name="l00289"></a>00289     vector&lt;PointOfView&gt;::iterator itPoV = camReal.begin();
<a name="l00290"></a>00290     <span class="keywordtype">int</span> index_image=0;
<a name="l00291"></a>00291     <span class="keywordflow">while</span> ( itPoV!=camReal.end() )
<a name="l00292"></a>00292     {
<a name="l00293"></a>00293       cv::Mat imgTmp=sequence_.getImage(index_image);<span class="comment">//get the current image</span>
<a name="l00294"></a>00294       <span class="keywordflow">if</span>(imgTmp.empty())
<a name="l00295"></a>00295         <span class="keywordflow">break</span>;<span class="comment">//end of sequence: quit!</span>
<a name="l00296"></a>00296       index_image++;
<a name="l00297"></a>00297 
<a name="l00298"></a>00298       <span class="comment">//create the vector of 3D points viewed by this camera:</span>
<a name="l00299"></a>00299       vector&lt;cv::KeyPoint&gt; points2DOrigine;
<a name="l00300"></a>00300       vector&lt;cv::Vec2d&gt; pixelProjected=itPoV-&gt;project3DPointsIntoImage(points3D);
<a name="l00301"></a>00301       <span class="comment">//convert Vec2d into KeyPoint:</span>
<a name="l00302"></a>00302       vector&lt;cv::KeyPoint&gt; points2D;
<a name="l00303"></a>00303       <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j=0;j&lt;pixelProjected.size();j++)
<a name="l00304"></a>00304         points2D.push_back( cv::KeyPoint( (<span class="keywordtype">float</span>)pixelProjected[j][0],
<a name="l00305"></a>00305         (<span class="keywordtype">float</span>)pixelProjected[j][1], 10.0 ) );
<a name="l00306"></a>00306 
<a name="l00307"></a>00307       cv::Mat imgTmp1,imgTmp2;
<a name="l00308"></a>00308       cv::drawKeypoints(imgTmp,points2DOrigine,imgTmp1,cv::Scalar(255,255,255));
<a name="l00309"></a>00309       cv::drawKeypoints(imgTmp,points2D,imgTmp2,cv::Scalar(255,255,255));
<a name="l00310"></a>00310       cv::imshow(<span class="stringliteral">&quot;Points origine...&quot;</span>,imgTmp1);
<a name="l00311"></a>00311       cv::imshow(<span class="stringliteral">&quot;Points projected...&quot;</span>,imgTmp2);
<a name="l00312"></a>00312       cv::waitKey(0);
<a name="l00313"></a>00313       itPoV++;
<a name="l00314"></a>00314     }
<a name="l00315"></a>00315   }
<a name="l00316"></a>00316 }
</pre></div></div>
</div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Variables</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<hr class="footer"/><address class="footer"><small>Generated on Mon Jul 25 2011 12:41:00 for GSoC2011SfM by&#160;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.7.4 </small></address>
</body>
</html>
